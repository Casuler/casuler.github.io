---
title: 人工智能导论
author: 四宮かぐや
date: 2022-06-14
updated: 2022-06-14
categories:
  - 学习笔记
tags:
  - 笔记
  - 后端
---



---

人工智能基础课程笔记总结

---

# 人工智能导论

## 第一章 绪论

### 1.1 人工智能的起源与定义

#### 起源

现代人工智能起源于1956年达特茅斯会议

参加者有：麦卡锡,明斯基,香农,罗切斯特,纽厄尔,西蒙,撒缪尔,伯恩斯坦,摩尔,所罗门诺夫。 前四位是发起人。

------

#### 定义

达特茅斯会议预期设想是:

…从理论上讲,学习的每一个方面或智能的任何其他特征,原则上都可以被精确地描述,以至于可以用机器来模拟它。我们将试图找到如何让机器使用语言,形成抽象和概念,解决目前留给人类的各种问题,并提高自身。<br>
$$
\text{(…every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves.)}
$$

目前最常见的定义有两个：

​	1. 明斯基提出：人工智能是一门科学,是使机器做那些人需要通过智能来做的事情

​	2. 更专业一些的定义,由尼尔森提出：人工智能是关于知识的科学。	知识的科学：研究知识的**表示**,知识的**获取**和知识的**运用**。

------

### 1.2 人工智能的流派

知识的基本单位是概念。	知识本身也是一个概念。

三个问题：如何定义(表示)一个概念,如何学习一个概念,如何应用一个概念

------

#### 概念的定义
1. 概念的符号表示。即概念的名称,简称概念名
2. 概念的内涵表示。由命题来表示,命题是能判断真假的陈述句。
3. 概念的外延表示。由经典集合来表示,用来说明与概念对应的实际对象是哪些

$eg.$素数

概念名：中文 --- 素数  英文 --- prime number

内涵表示：只能被1和自身整除的大于1的自然数

外延表示：$\{2,3,5,7,11,13,17,……\}$

------

#### 概念的作用或功能

1.指物功能,指向客观世界的对象的可观测性

2.指心功能,指向人心智世界里的对象

3.指名功能,指向认知世界或者符号世界表示对象的符号名称

波普尔的三个世界理论：认知世界,物理世界,心理世界

掌握一个概念需要知道这个概念的三个指向。

------

#### 三个流派

符号主义,连接主义,行为主义(自然主义)

------

##### 符号主义

符号主义认为只要在机器上是正确的,现实世界就是正确的。即指名对了,那么指物也是对的。

$eg.$图灵测试

###### 现实挑战

1.概念的组合爆炸问题。组合概念无穷尽

2.命题的组合悖论问题。两个合理命题组合起来成为悖论

3.经典概念再实际生活中很难得到,知识难以提取。

------

##### 连接主义

连接主义认为大脑是一切智能的基础。通过研究人脑的神经元及其连接机制,在机器上进行模拟。

$eg.$缸中之脑实验,$AlphaGo$

###### 现实挑战

不清楚人脑表示概念的机制,不清楚概念的具体表示形式,表示方式和组合方式等等。

现在的神经网络与深度学习实际上与人脑机制差距尚远。

------

##### 行为主义

行为主义假设只能取决于感知和行动,不需要知识,表示和推理。即只要能实现指物功能就可以认为具有智能。

$eg.$六足爬行机器人

###### 现实挑战

莫拉维克悖论

------

## 第二章 概念表示

### 2.1 经典概念理论

定义：一个经典概念由概念名,概念的内涵表示,概念的外延表示组成。

------

**概念名**由一个**词语**来表示,属于**符号世界**或者认知世界。

**概念的内涵表示**用命题来表示,反映和揭示概念的本质属性,是人类主观世界对概念的认知,可存在于人的心智之中,属于**心智世界**。

**概念的外延表示**由概念指称的具体实例组成,是一个由满足概念的内涵表示的对象构成的**经典集合**。概念的外延表示外部可观可测。

经典概念大多隶属于科学概念。$eg.$偶数,英文字母属于经典概念。

------

#### 命题

能表达判断的陈述句,真值必须唯一。

------

### 2.4概念的现代表示理论

不是所有概念都具有经典概念表示。

------

#### 新概念表示理论

------

##### 原型理论

一个概念可由一个原型来表示。	一个原型既可以是一个实际的或者虚拟的对象样例,也可以是一个假设性的图示性表征。

------

##### 样例理论

概念不可能有一个对象样例或者原型来代表,但是可以由多个已知样例来表示。

------

###### 样例表示的三种不同形式：

由该概念的所有已知样例来表示

由该概念的已知最佳,最典型或者最常见的样例来表示

由该概念的经过选择的部分已知样例来表示

------

##### 知识理论

概念是特定知识框架(文明)的一个组成部分。

------

概念在人心智中的表示称为认知表示,其属于概念的内涵表示。

------

## 第三章 知识表示

### 3.1 知识与知识表示的概念

#### 3.1.1 知识的概念

知识是人们在长期的生活及社会实践中,在科学研究及实验中积累起来的对客观世界的认识与经验。

定义：把有关信息关联在一起所形成的信息结构称为知识。

#### 3.1.2 知识的特性

相对正确性,不确定性,可表示性与可利用性

#### 3.1.3 知识表示的概念

知识表示就是将人类知识形式化或者模型化。

### 3.2 产生式表示法

产生式表示法又称为产生式规则表示法。

------

#### 3.2.1 产生式

适用于表示事实性知识和规则性知识。

------

##### 1.确定性规则的产生式表示

基本形式：
$$
IF \quad P \quad THEN \quad Q
$$
或者
$$
P \quad → \quad Q
$$
其中,$P$是产生式的前提,用于指出该产生式是否可用的条件；$Q$是一组结论或操作,用于指出当前提P所指示的条件满足时,应该得出的结论或应该执行的操作。

含义：如果前提$P$被满足,则结论$Q$成立或执行$Q$所规定的操作。

$eg.$
$$
r_4: \quad IF \quad \text{动物会飞} \quad AND \quad \text{会下蛋} \quad THEN \quad \text{该动物是鸟}
$$
$r_4$是该产生式的编号；“动物会飞$AND$会下蛋”是前提$P$；“该动物是鸟”是结论$Q$

------

##### 2.不确定性规则的产生式表示

基本形式：
$$
IF \quad P \quad THEN \quad Q \quad \text{(置信度)}
$$
或者
$$
P \quad → \quad Q \quad \text{(置信度)}
$$
$eg.$专家系统MYCIN中一条产生式：
$$
IF \quad \text{本微生物的染色斑是革兰氏阴性,本微生物的形状呈杆状,患者是中间宿主} \quad THEN \quad \text{该微生物是绿脓杆菌} \quad (0.6)
$$
它表示当前提中列出的各个条件都得到满足时,结论“该微生物时绿脓杆菌”可以相信的程度为0.6

0.6表示知识的强度

------

##### 3.确定性事实的产生式表示

确定性事实一般用三元组表示
$$
\text{(对象,属性,值)}
$$
或者
$$
\text{(关系,对象1,对象2)}
$$
例如,“老李的年龄是40岁”表示为$(Li,Age,40)$,“老李和老王是朋友”表示为$(Friend,Li,Wang)$

------

##### 4.不确定的事实产生式表示

不确定事实一般用四元组表示
$$
\text{(对象,属性,值,置信度)}
$$
或者
$$
\text{(关系,对象1,对象2,置信度)}
$$
例如,“老李的年龄很可能是40岁”表示为$(Li,Age,40,0.8)$,“老李和老王不大可能是朋友”表示为$(Friend,Li,Wang,0.1)$

置信度0.1表示可能性较小



产生式又称为规则或产生式规则；产生式的“前提”有时称为“条件”,“前提条件”,“前件”,“左部”等；“结论”有时称为“后件”,“右部”等。

------

### 3.3 框架表示法

框架表示法是一种结构化的知识表示方法。

框架是一种描述所论对象(一个事物,事件或概念)属性的数据结构。

一个框架(frame)由若干个被称为“槽”(slot)的结构组成,每一个槽又可根据实际情况分为若干个“侧面”(facet)。

------

### 3.4 状态空间表示法

状态空间是利用状态变量和操作符号符号表示系统或问题的有关知识的符号体系。

状态空间可以用一个四元组表示：
$$
(S,O,S_0,G)
$$
$S$是状态集合,每一个$S$的元素表示一个状态,状态时某种结构的符号或数据。

$O$是操作算子的集合,利用算子可将一个状态转换为另一个状态。

$S_0$是问题的初始状态的集合,是S的非空子集,即${S_0}\subset{S}$。

$G$是问题的目的状态的集合,是S的非空子集,即$G\subset{S}$。

$G$可以是若干具体状态,也可以是满足某些性质的路径信息描述。

------

## 第四章 知识图谱

**知识图谱**：是结构化的语义知识库,用于以符号形式描述物理世界中的概念及其相互关系。其基本组成单位是$\text{(实体,关系,实体)}$三元组,以及实体及其相关属性键值对,实体间通过关系互联,构成网状的知识结构。

定义：知识图谱是以图的形式表示客观世界中实体$\text{(人,事物,概念)}$及其之间关系的知识库。

------

概念指人们在认识世界过程中形成的对客观事物的概化表示,如人,动物,组织机构等。

实体指客观世界中的具体事物,如画家达芬奇,篮球运动员姚明等。

关系描述概念,实体间客观存在的关联,如艺术家和画家间的上下位关系,姚明和篮球运动员间的隶属关系,学生与其所在院校间的毕业院校关系等。

------

## 第五章 搜索技术

### 5.2 盲目搜索

定义：如果搜索过程中没有利用任何与问题有关的知识或启发信息,则称之为盲目搜索。

------

#### 5.2.1 深度优先搜索(有限深度搜索,迭代深度搜索)

基本思想：优先扩展深度最深的节点。

$eg.$ $N$皇后问题,八数码问题

八数码问题：深度优先搜索虽然不能保证找到最优解,但可以采用回溯的方法,只保留从初始节点到当前节点的一条路径即可,大大节省存储空间。其所需要的存储空间与搜索深度呈线性关系。

------

#### 5.2.2 宽度优先搜索

基本思想：优先搜索深度浅的节点进行扩展,如果有深度相同的节点,则按事先约定从中选择一个。

$eg.$八数码问题

宽度优先搜索会保留已有的搜索结果,需要占用较大的搜索空间,并随着搜索深度加深几何级数增加。

### 5.3 启发式搜索

八数码问题

------

#### $A$算法

评价函数：
$$
f(n)=g(n)+h(n)
$$
$n$为待评价的节点；

$g(n)$为初始节点$s$到节点$n$的最佳路径耗散值的估计值；$h(n)$为从节点$n$到目标节点$t$的最佳路径耗散值的估计值,称为启发函数；$f(n)$为从初始节点$s$经过节点$n$到达目标节点$t$的最佳路径耗散值的估计值,称为评价函数。

耗散值：路径的代价,可以是时间,长度,费用等。

------

#### $A^*$算法

在$A$算法的基础上,对启发函数$h(n)$满足下列条件
$$
h(n)≤h^*(n)
$$
则可以证明当问题有解时,$A$算法一定可以得到一个耗散值最小的结果,即最佳解。

------

### 5.4 博弈搜索

------

#### α-β剪枝算法

利用已经搜索过的状态对搜索进行剪枝,提高搜索效率。

------

#### 蒙特卡洛树搜索方法

搜索过程：选择-扩展-模拟-回传

------

## 第六章 群智能算法

### 6.2 遗传算法

------

#### 三种基本遗传算子

选择算子,交叉算子,变异算子

------

#### 五个基本要素

参数编码,初始群体的设定,适应度函数的设计,遗传操作设计和控制参数设定

------

#### 特点

1.遗传算法的编码操作可以直接对结构对象进行操作。

2.遗传算法采用群体搜索策略,即采用同时处理群体中多个个体的方法。

3.遗传算法仅用适应度函数值来评估个体,并在此基础上进行遗传操作,使种群中个体之间进行信息交换。

------

### 6.3 粒子群优化算法

受鸟类群体行为启发提出的仿生全局优化算法。

将群体中的每一个个体看作$n$维搜索空间中的一个没有体积,没有质量的粒子,在搜索空间中以一定的速度飞行,通过群体中粒子间的合作与竞争产生的群体智能指导优化搜索。

------

#### 算法流程

- 初始化粒子,设置初始值
- 计算粒子的适应度
- 获取每个粒子的历史最优位置和群体最优位置
- 比较并更新群体最优位置
- 判断是否满足条件,满足则输出结果,否则返回第二步

------

#### 参数分析

##### 最大速度$V_{max}$

对于速度$V_i$,算法中由最大速度$V_{max}$作为限制。若当前粒子某维速度大于最大速度$V_{max}$,则该维的速度被限制为$V_{max}$

$V_{max}$决定当前位置与最好位置之间的区域的分辨率(精度)。若$V_{max}$太大,粒子可能飞过最好的解；若$V_{max}$太小,粒子容易陷入局部最优解。

##### 权重因子。惯性权重$\omega$,加速度常数$\phi_1$与$\phi_2$

###### 惯性权重$\omega$

使粒子保持运动惯性,使其由扩展搜索空间的趋势,有能力搜索新的区域

###### 加速度常数$\phi_1$和$\phi_2$

代表将每个粒子推向$P_i$和$P_g$位置的统计加速度项的权重。低的值允许例子在被拉回之前可以在目标区域外徘徊,而高的值则导致粒子突然冲向或越过目标区域。

------

### 6.4 蚁群算法

------

全局最优化搜索算法

改进：

​	最优解保留策略(精华蚂蚁系统)

​	基于排序的蚂蚁系统

#### 6.4.2 基本算法

优点：正反馈,分布式,启发式搜索,鲁棒性强

缺点：搜索时间长,容易出现停滞现象

------

设蚁群中蚂蚁的数量为$m$,$d_{xy}(x,y=1,……,n)$表示元素(城市)$x$和元素(城市)$y$之间的距离。

$\eta_{xy}(t)$表示能见度,称为启发信息函数,等于距离的倒数,即$\eta_{xy}(t)=\frac{1}{d_{xy}}$。

$b_x(t)$表示时刻t位于城市$x$的蚂蚁的个数,$m=\sum_{x=1}^{n}b_x(t)$。$\tau_{xy}(t)$表示$t$时刻在$xy$连线上残留的信息素。

在初始时刻,各条路径上的信息素相等,即$\tau_{xy}(0)=C(const)$。蚂蚁$k(k=1,……,m)$

在运动过程中,根据各条路径上的信息素决定转移方向。

$P_{xy}^k(t)$表示在$t$时刻蚂蚁$k$选择从元素(城市)$x$转移到元素(城市)$y$的概率,由信息素$\tau_{xy}(t)$和局部启发信息$\eta_{xy}(t)$共同决定,也称为随机比例规则。

$$
P_{xy}^k(t)= \begin{cases} \frac{[\tau_{xy}(t)]^\alpha[\tau_{xy}(t)]^\beta}{\sum_{y\in allowed_k(x)}^{[\tau_{xy}(t)]^\alpha[\eta_{xy}(t)]^\beta}},\quad if\quad y\in allowed_k(x)\\ 0,\quad \text{否则} \end{cases}
$$
其中,$allowed_k(x)=\{0,1,……,n-1\}-tabu_k(x)allowed_k(x)=\{c-tabu_k(x)\}$表示蚂蚁$k$下一步允许选择的城市。

$tabu_k(x)(k=1,2,……,m)$记录蚂蚁$k$当前所走过的城市。

$\alpha$是信息素启发式因子,表示轨迹的相对重要性,反映了残留信息浓度$\tau_{xy}(t)$在指导蚁群搜索中的相对重要程度。

$\alpha$值越大,该蚂蚁越倾向于选择其他蚂蚁经过的路径,该状态转移概率越接近于`贪婪规则`。

当$\alpha=0$时,算法就是`传统的贪心算法`；而当$\beta=0$时,算法就是纯粹的`正反馈的启发式算法`。

------

随着时间推移,信息素会逐渐消逝,用参数$1-\rho$表示信息素消逝程度。蚂蚁完成一次循环,各路径上信息素浓度消散规则如下：(蒸发系数)
$$
\tau_{xy}(t+1)=\rho\tau_{xy}(t)+\Delta\tau_{xy}(t)
$$
路径$(x,y)$上信息素的增量$\Delta\tau_{xy}(t)$为：
$$
\Delta\tau_{xy}(t)=\sum_{k=1}^m{\Delta\tau_{xy}^k(t)}
$$

------

$M.Dorigo$给出$\Delta\tau_{xy}^k(t)$的一种模型,称为`蚂蚁圈系统`。第$k$只蚂蚁留在路径$(x,y)$上的信息素的增量$\Delta\tau_{xy}^k(t)$为：
$$
\Delta\tau_{xy}^k(t)=\begin{cases} \frac{Q}{L_k},\quad \text{若第k只蚂蚁在本次循环中从x到y|,\\\ 0,\quad 否则}\end{cases}
$$
其中,$Q$为常数；$L_k$为优化问题的目标函数值,表示第$k$只蚂蚁在本次循环中所走路径的长度。

------

#### 6.4.3 蚁群算法参数选择

##### 信息素启发因子$\alpha$

信息素启发因子$\alpha$的大小反映了蚁群在路径搜索中随机性因素作用的强度。

$\alpha$越大,蚂蚁选择以前走过的路径的可能就越大,搜索的随机性减弱；当$\alpha$过大时,蚁群搜索会过早的陷入局部最优。

##### 期望值启发因子$\beta$

期望值启发因子$\beta$的大小反映了蚁群在路径搜索中先验性,确定性因素作用的强度。

$\beta$值越大,蚂蚁在某个局部点上选择局部最短路径的可能就越大,收敛速度加快,但蚁群搜索随机性减弱,会陷入局部最优。

$\alpha\text{和}\beta$对蚁群算法性能的影响是相互配合,密切相关的。

------

#### 6.4.4 蚁群算法的应用

$eg.$车间调度问题,车辆路径问题,旅行商问题

------

## 第七章 机器学习

数据降维：特征选择,特征提取

特征选择后的特征是原来特征的一个子集

------

### 基本概念

数据集$Dataset$：所有数据的集合

样本$Sample$：每一条记录

属性$attribute$/特征$feature$：样本某方面的特质(表现或性质)

特征向量$feature vector$：样本特征对应特征空间中的一个坐标向量

机器学习的定义：让机器能像人一样具有学习能力

`经典定义`：利用经验来改善计算机系统自身的性能

机器学习的目标：从数据中学习相应的“模型”$model$

------

### 分类

监督学习,无监督学习,弱监督学习

------

#### 7.2 监督学习(有教师学习)

在已知输入输出的情况下训练出一个模型,将输入映射到输出。

------

##### 7.2.1 K-近邻算法(KNN算法)

适用于多分类问题。核心思想是排队。

优点：简单容易实现,支持多分类,不需要训练,可以用训练数据实现分类

缺点：对参数的选择很敏感,计算量大

------

##### 7.2.2 决策树

代表对象属性与对象值之间的一种映射关系。

基于树结构决策。一般包含一个根节点,若干个内部节点和若干个叶节点。

每个内部节点表示一个属性上的测试,每个分支表示一个测试输出,每个叶节点表示一种类别

策略：分而治之

优点：①易于理解和实现 ②不需要准备大量数据,可以同时处理数据型和常规型属性

提高纯度：信息增益(ID3算法),增益率(C45算法),基尼指数(CART算法)

奥卡姆剃刀原则：统一性,对称性,简单性

过拟合(采用预剪枝),欠拟合(采用后剪枝)

------

##### 7.2.3 支持向量机SVM(逻辑回归算法的强化)

二分类模型

------

###### 最大间隔准则

距离超平面最近的几个训练样本点被称为“支持向量”,两个异类支持向量到超平面的距离之和称为“间隔”,支持向量机的目标是找到具有“最大间隔”的划分超平面。

超平面方程：$\omega^Tx+b=0$			 $r=\frac{2}{||\omega||}$

------

###### 近线性可分问题

线性不可分或本质线性可分,因噪音不可分

需要将低维空间映射到高维空间

$eg.$一维→二维  $x→(x,x^2)$增加计算量,反之高维映射到低维减少计算量。

$eg.$二维→三维 $P(x,y)=(x^2,\sqrt{2}xy,y^2)$

$<P(v_1),P(v_2)>=K(v_1,v_2)=<v1,v2>^2$

$eg.(x_1z_1+x_2z_2)^2$

核函数：$k(v_1,v_2)=<v_1,v_2>^2$内积平方

①低维到高维的映射

②计算简便

#### 7.3 无监督学习

区别：有无数据标识

多类别$k$均值聚类算法过程

聚类,关联/降维(概率分布)

------

##### 聚类

划分聚类,层次聚类,密度聚类,网格聚类,混合聚类

高质量聚类结果-簇

------

###### $K-$均值算法

贪心算法,迭代实现
$$
E=\sum_{i=1}^k\sum_{X\in C_i}||X-\mu_i||_2^2
$$
贝叶斯算法：先验概率,后验概率

朴素贝叶斯分类器：基于出现概率进行粗略的分类

先验概率×每个属性的条件概率

K-Means划分聚类

#### 7.4 弱监督学习

------

##### 7.4.1 半监督学习

聚类假设,流行假设

半监督分类/回归/聚类/降维

自(学习)训练

优点：简单,易实现

缺点：误差会在自我迭代过程中放大

$eg.$语音识别,文本分类,词义解析,视频监控,蛋白质预测……

------

##### 7.4.2 迁移学习

举一反三

###### 实现方式

①样本迁移 ②特征迁移 ③模型迁移

------

##### 7.4.3 强化学习

处理决策问题,与环境交互学习,给出策略(延迟)回报

------

## 第八章 人工神经网络与深度学习

### 8.1 神经网络的发展历史

BP算法,浅层学习方法,深度学习。

### 8.2 神经元与神经网络

#### 8.2.1 生物神经元结构

神经元：细胞体(细胞核,细胞质,细胞膜……),树突,轴突(轴突末梢)

轴突用来传递和输出信息,其端部的轴突末梢为信号输出端子,将神经冲动传递给其他神经元。

树突相当于输入端,全长各点都能接收其他神经元的冲动。

神经冲动只能由前一级神经元的轴突末梢传递给下一级神经元的树突或细胞体,不能反向传递。

脑神经信息活动特征：①巨量并行性 ②信息处理和存储单元结合在一起 ③自组织自学习功能

#### 8.2.2 神经元数学模型

一种标准统一的数学模型：加权求和,线性动态系统和非线性函数映射

线性环节最常见的是比例系数,常用的非线性激励函数有：

##### ①阶跃函数

$$
f(x_i)=\begin{cases}1\quad x_i>0\\0\quad x_i≤0 \end{cases}
$$

对于需要神经元输出在$[-1,1]$区间时,阶跃函数可取为：
$$
f(x_i)=\begin{cases}1\quad x_i>0\\-1\quad x_i≤0 \end{cases}
$$

##### ②$S$型函数

具有平滑和渐进性,保持单调性,最常用的是$Sigmoid$函数
$$
f(x_i)=\frac{1}{1+{e}^{-\alpha x_i}}
$$
$\alpha$可以控制斜率

对于需要神经元输出在$[-1,1]$区间时,$S$型函数可以选为双曲线正切函数
$$
f(x_i)=\frac{1-{e}^{-\alpha x_i}}{1+{e}^{-\alpha x_i}}
$$
$Sigmoid$函数缺点：输入的绝对值大于某个阈值后,过快进入饱和状态,出现梯度消失的情况,导致模型收敛缓慢,性能差。

③$ReLU$函数

今年深度学习广泛使用的一个激活函数
$$
f(x_i)=\begin{cases}0\quad x_i<0\\x_i\quad x_i≥0\end{cases}
$$
形式简单,没有饱和问题,运算速度快,收敛效果好,常用于卷积神经网络等深度神经网络。

#### 8.2.3 神经网络的结构

拓扑结构：层次网络模型|互联网络模型

前馈型：各神经元接受前一层的输入并输出给下一层,没有反馈。

反馈型：一些神经元的输出经过若干个神经元后,再反馈到这些神经元的输入端。

全连接(全互联)：每个神经元和其他神经元相互连接

------

### 8.3 BP神经网络及其学习算法

前馈型神经网络

BP神经网络时多层前向网络。全连接,层间无反馈,有监督学习,S型函数激活。

BP学习算法：

$N\text{组输入输出样本为}\{X_{si},Y_{si}\},i=1,2,……,N$

输入为样本$X_{si}$,输出为样本$Y_{si}$

实际输出$Y_j^m$
$$
\Delta w_{ij}^{k-1}=-\epsilon d_i^ky_j^{k-1}\\
d_i^m=y_i^m(1-y_i^m)(y_i^m-y_{si})\\
d_i^k=y_i^k(1-y_i^k)\sum_{l}d_l^{k+1}w_{li}^k\quad(k=m-1,……,2)
$$
$\epsilon$为学习步长,一般小于$0.5$。

### 8.4 卷积神经网络(CNN)

#### 8.4.2 结构

输入层,卷积层,激活层,池化层,全连接FC层

激活函数：$ReLU,\text{SOFTMAX多分类},\text{归一化指数函数}$

输入层通常是一个矩阵

卷积层是特征提取层

池化层(下采样层)是特征映射层

##### 关键技术

局部连接(降低参数量,提高计算效率),权值共享,多卷积核,池化(特征不变形,特征降维,一定程度防止过拟合|平均池化,最大池化方法)

#### 8.4.3 卷积计算

$SOFTMAX$用于最后一层计算输出

输入矩阵*卷积核(点积|内积)

##### 实例

不适用于大规模图像处理

### 8.5 生成对抗网络

两个角色：生成器,判别器

生成器：通过噪声,生成伪数据

判别器：对输入的图片x(可能采样于真实数据,可能采样于伪数据)进行判断,输出标量,为判断是否是真实图片的概率1|0

#### 应用

图像和视频生成,文本生成,从文本生成图像

#### 8.6 深度学习应用

网络结构在4-5层以上是深度学习

## 第九章 专家系统

核心：知识库与推理机

知识库：领域强相关

推理机：具有一定的通用性

知识库用于存储求解问题所需的领域知识和事实等,一般表示如下：
$$
IF\quad \text{<前提>}\quad THEN\quad \text{<结论>}
$$
表示当<前提>被满足时,可以得到<结论>

$eg. IF\quad \text{阴天}and\text{湿度大}\quad THEN\quad \text{下雨}$

表示：如果阴天且湿度大,则会下雨

### 结构

推理机：执行结构,负责对知识库内的知识进行解释,利用知识进行推理

动态数据库：工作存储区,存放初始已知条件,已知事实,推理过程中得到的中间结果以及最终结果等

人机交互界面：系统与用户的交互接口,用户输入数据,系统显示信息给用户

解释器：专家系统特有模块,如果用户有希望系统解释的内容,专家系统通过解释器对用户进行解释。“How解释”和“Why解释”

“Why解释”回答“为什么”,“How解释”回答“如何得到”

### 局限性

知识获取存在瓶颈,知识库时有限的,专家系统只能描述特定的领域,不具备通用性,难以适配知识的变化和更新

## 第十章 计算机视觉

研究如何对数字图像或视频进行高层理解的交叉学科

2种模型：深度模型和学习方法,浅层模型和学习方法

## 第十一章 自然语言处理

NLP：自然语言处理,研究人类与计算机之间通过自然语言进行有效通信的方法和理论

机器翻译三个阶段：

第一阶段：基于规则建立词汇,句法语义分析,问答,聊天和机器翻译系统

第二阶段：基于统计的机器学习

第三阶段：深度学习,语音和图像

应用现状：

神经机器翻译,智能人机交互,阅读理解,机器创作

注意力机制：提高了编码器解码器框架在长句子上的翻译质量

对话系统三大模块：对话理解,对话管理,回复生成

## 第十二章 语音处理

语音是人类通过发音器官发出来的,具有一定意义的,目的是用来社会交际的声音

语音识别系统：特征提取,声学模型,语言模型,解码搜索

语音增强：回声消除,混响抑制,语音降噪

## 第十三章 规划

两大任务：问题描述,问题求解

经典规划不确定性：①信息不完全性 ②不可预测性 ③行动不确定性

解决方法：①重规划 ②条件规划

经典规划问题求解：

①前向搜索 ②后向搜索 ③启发式搜索

## 第十四章 多智能体系统

智能体是一个`软件实体`,其可以代表一个人类用户或其他程序。智能体具有一个`行为集合`,且具有某种程度的`独立性`和`自主性`。智能体在采取行为时,通常使用某些`知识`来表示用户的`目标`或者`期望`。

四种性质：①自主性 ②主动性 ③反应能力 ④社会能力

强性质：①移动性 ②诚实性 ③无私性 ④理性

### 智能体的环境

①确定性|非确定性

②可访问|不可访问

③场景式|非场景式

④静态|动态

⑤离散|连续

#### BDI结构

三个关键要素：信念,期望,意图

四函数：修正函数,选择函数,过滤函数,动作函数

### 多智能体协商

纳什均衡解和帕里托优解,投票,拍卖,谈判

谈判最优解性质：①不变性 ②对称性 ③无关方案的独立性 ④帕里托优

## 第十五章 智能机器人

应用：视觉,触觉,听觉,多模态信息融合
